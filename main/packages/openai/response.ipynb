{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request\n",
    "\n",
    "OpenAI's `text` generation models have been trained to understand natural and formal language.  \n",
    "The inputs to these models are also referred to as `prompts`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Flask?\n",
      "Flask is a lightweight web framework written in Python\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Setup OpenAI API key\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# User question\n",
    "question = \"What is Flask?\"\n",
    "print(\"Question:\", question)\n",
    "\n",
    "# API response (short answer)\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": question}],\n",
    "    max_tokens=10,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "answer = response['choices'][0]['message']['content']\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Completion\n",
    "\n",
    "Streaming completion is an essential functionality for `real-time` text generation applications.  \n",
    "In the context of OpenAI, streaming completions refer to the ability to receive a stream of `tokens`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Flask?\n",
      "Flask is a lightweight web framework for Python that allows developers to build web applications quickly and efficiently. It is designed to be simple and easy to use, with a modular structure that allows developers to customize and add functionality as needed. Flask provides various features such as routing URLs to functions, rendering templates, handling form data, and integrating with databases. It is often used for building small to medium-sized web applications and APIs."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os, sys\n",
    "\n",
    "# Setup OpenAI API key\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "question = \"What is Flask?\" \n",
    "print(\"Question:\", question)\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": question}],\n",
    "    max_tokens=256,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "    print(content, end=\"\", flush=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation History\n",
    "\n",
    "You can use the GPT API to create a conversation where the model `remembers` the context.   \n",
    "You'll need to maintain the conversation history and include that history in `subsequent` requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What is Flask? Keep the answers short.\n",
      "Flask is a lightweight web framework in Python.\n",
      "Question: What's the current version?\n",
      "The current version of Flask is 2.0.1."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os, sys\n",
    "\n",
    "# Setup OpenAI API key\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Question stream\n",
    "questions = [\n",
    "    \"What is Flask? Keep the answers short.\",\n",
    "    \"What's the current version?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(\"\\nQuestion:\", question)\n",
    "\n",
    "    # Add user question to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation_history,\n",
    "        max_tokens=64,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in response:\n",
    "        content = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "        print(content, end=\"\", flush=True)\n",
    "\n",
    "    # Add API response to converstion history\n",
    "    conversation_history.append({\"role\": \"system\", \"content\": content})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Message\n",
    "\n",
    "You can add a context message at the `start` of the conversation to instruct the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What is Flask? Keep the answers short.\n",
      "Flask is a web framework for Python.\n",
      "Question: What's the current version?\n",
      "The current version of Flask is 2.0.1."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os, sys\n",
    "\n",
    "# Setup OpenAI API key\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Context for keeping answers short\n",
    "context_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"System: Please keep the answers short\"\n",
    "}\n",
    "conversation_history.append(context_message)\n",
    "\n",
    "# Question stream\n",
    "questions = [\n",
    "    \"What is Flask? Keep the answers short.\",\n",
    "    \"What's the current version?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(\"\\nQuestion:\", question)\n",
    "\n",
    "    # Add user question to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation_history,\n",
    "        max_tokens=64,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in response:\n",
    "        content = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "        print(content, end=\"\", flush=True)\n",
    "\n",
    "    # Add API response to converstion history\n",
    "    conversation_history.append({\"role\": \"system\", \"content\": content})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://levelup.gitconnected.com/build-your-own-question-answering-system-with-openai-and-flask-2200507ac601\n",
    "https://platform.openai.com/docs/quickstart?context=python  \n",
    "https://blog.finxter.com/python-openai-streaming-completions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
